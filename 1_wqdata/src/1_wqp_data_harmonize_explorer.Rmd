---
title: "WQP Parameter and Method Harmonization"
output:
  html_document:
    toc: true
editor_options: 
  chunk_output_type: console
---

# Harmonizing disparate data

The data from the water quality portal includes a wide range of methods and characteristic names. For example in the "chlorophyll" this can be chlorophyll a, b, or both and retrieved using a variety of methods. To know which methods and characteristic names to keep and use, we must first get a better understanding of the type of data we have. 

Here we are harmonizing the entirety of the water quality portal data even though the vast majority of these sites will not be landsat visible. The computation time to do it for a few extra million samples is not onerous and the intermediate mostly harmonized full dataset will likely be useful for other uses. 



```{r setup, include=F, warnings='hide'}
library(feather)
library(tidyverse)
library(knitr)
library(kableExtra)
library(pander)
library(LAGOSNE)
library(lubridate)
library(GenKern) #For nearest function
library(scipiper)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir='../..')

```


```{r functions}

#Define a function that renames and reorders columns from the raw files
wqp.renamer <- function(df){
  simple.names <- df %>%
                  dplyr::select(date=ActivityStartDate,
                         parameter=CharacteristicName,
                         units=ResultMeasure.MeasureUnitCode,
                         SiteID=MonitoringLocationIdentifier,
                         org=OrganizationFormalName,
                         org_id=OrganizationIdentifier,
                         time=ActivityStartTime.Time,
                         value=ResultMeasureValue,
                         sample_method=SampleCollectionMethod.MethodName,
                         analytical_method=ResultAnalyticalMethod.MethodName,
                         particle_size=ResultParticleSizeBasisText,
                         date_time=ActivityStartDateTime,
                         media=ActivityMediaName,
                         sample_depth=ActivityDepthHeightMeasure.MeasureValue,
                         sample_depth_unit=ActivityDepthHeightMeasure.MeasureUnitCode,
                         fraction=ResultSampleFractionText,
                         status=ResultStatusIdentifier) %>%
  #Remove trailing white space in labels
  mutate(units = trimws(units)) %>%
  #Keep only samples that are water samples
  filter(media=='Water')
  dropped = nrow(df)-nrow(simple.names)
  print(paste('we dropped',dropped,'samples because the sample medium was not labeled as Water'))
  return(simple.names)
}

#Function for making a nice table that gets a summary of units and the number of observations with that unit code
unit.kable <- function(d){
  d %>%
    group_by(units) %>%
    summarize(count=n()) %>%
    arrange(desc(count)) %>%
    kable(.,'html',caption='All  parameter and unit combinations') %>%
    kable_styling() %>%
    scroll_box(width='500px',height='400px')
}

unit.disharmony <- function(d,lookup){
  d %>%
    anti_join(lookup,by='units') %>%
    group_by(units) %>%
    summarize(count=n())  %>%
    kable(.,'html',caption='The following measurements
          were dropped because the units do not make sense') %>%
    kable_styling() %>%
    scroll_box(width='500px',height='400px')
}

sample.kable <- function(d){
d %>%
  group_by(sample_method) %>%
  summarize(count=n()) %>% 
  arrange(desc(count)) %>%
  kable(.,'html',caption='All sample methods and their count') %>%
  kable_styling() %>%
  scroll_box(width='600px',height='400px')
}

analytical.kable <- function(d){
  d %>%
    group_by(analytical_method) %>%
    summarize(count=n()) %>% 
    arrange(desc(count)) %>%
    kable(.,'html',caption='All analytical methods and their count') %>%
    kable_styling() %>%
    scroll_box(width='600px',height='400px')
}

```

We'll start with the easiest first. Secchi depth


# Secchi depth

## Secchi Methods

The nice thing with secchi disk depth methods, is that the name explains the method and their are not really alternative methods so we will not filter this data by sampling or analytical method categories. 

## Secchi Unit Harmonization

In many ways, the secchi disk depth measurement is the easiest water quality parameter to harmonize, 
because there is really only 
one method for measuring secchi disk depth (it's in the name after all),
and there should always be units of depth (m, ft, inches, cm, etc...).
So to harmonize secchi depth measurements we simpy drop all units that are not units of depth and convert all units to a single kind with a lookup table. 

First let's make sure R is starting with a fresh memory clean because these datasets can get clogged. A call to gc() should clear any memory issues from previous scipiper work. 
```{r}
gc()
```


```{r secchi all parameters}
#Read in the raw data from '1_wqdata/out'
secchi <- read_feather('1_wqdata/out/wqp/all_raw_secchi.feather') %>%
  wqp.renamer() 
#Summarize by characteristic name and unit code and print
unit.kable(secchi)

```

### Secchi unit disharmony

Now that we can see all the units we have we can drop non-depth units and make a lookup table to convert all units to meters. 

```{r secchi illogical}
#Create a lookup table of units and conversion factors that we want to keep
secchi.lookup <- tibble(units=c('cm','ft','in','m','mi'),
                        conversion = c(0.01,.3048,0.0254,1,1609.34))

# Do an anti_join to these units so that all units that aren't kept can be highlighted and displayed
unit.disharmony(secchi,secchi.lookup)
```



### Secchi unit harmony in meters

```{r secchi sensible}
#Join secchi by unit name and then multiply by conversion factor to get meters
secchi.harmonized <- secchi %>%
  inner_join(secchi.lookup,by='units') %>%
  mutate(harmonized_parameter = 'secchi',
         harmonized_value=value*conversion,
         harmonized_unit='meters')

rm(secchi,secchi.lookup)
```



Next easiest is TSS

# TSS 

This [paper](https://water.usgs.gov/osw/pubs/WRIR00-4191.pdf) is really useful for exploring this data. In this paper, the USGS directly compares estimates of Suspended Sediment Concentration (SSC) and Total Suspended Solids (TSS). The primary difference between these methods, as laid out in this paper, is that SSC estimates the mass of suspended solids in a sample volume, by drying out the entire sample without subsampling the water volume. TSS methods often involve some form of subsampling of the total water volume. The paper highlights that while many estimates of TSS and SSC are essentially the same, samples with high sand content show systematic bias in TSS estimates. For our purposes, we have no apriori way to distinguish samples with high or low sand, so we have made the choice to assume that measurements of SSC and TSS are, over the bulk of samples, the same. We use the term "TSS" from here on to describe this data that is both SSC and TSS. 


```{r}
#Read in the raw data from '1_wqdata/out'
tss <- read_feather('1_wqdata/out/wqp/all_raw_tss.feather') %>%
  wqp.renamer()

#Summarize by characteristic name and unit code
unit.kable(tss)
```

## TSS methods

Now that we have made the decision to call SSC and TSS interchangeable depsite their slight methodological differences, we need to explore the various methods used to get TSS or SSC concentration estimates. Unlike with issues with units, we can not harmonize our way out of methods that don't make sense. So instead we will be filtering out these methods. 

There are essentially two important methods for thinking about TSS and SSC. The field method used to collect the water sample and the analytical method used to weigh out suspended sediment and total water volume. The sample methods are extremely verbose and varied, but mostly boil down to some version of sample collected in bottle of water. For posterity a table of sample method is reproduced here, but we do not filter based on sample method. 

### TSS sample methods

Many of these methods refer to other documents that were used as a protocol for sampling (EPA METHOD or USGS), but these also are versions of collecting water with a bottle, pump, or depth sampling equipment. 

```{r tss sample method}

sample.kable(tss)

```


### TSS analytical methods
Unlike with secchi disk depth measurements, there are a variety of analytical methods available to measure TSS. Many of these should provide similar results, but some can be used to highlight potential erroeneous data entry (Phosphorous content should not be a method of TSS calculation), but many of them are simply labeled by a state or federal protocol number, making trimming and evaluating these various methods difficult. Below is a table of all possible analytical methods and their count

```{r tss analytical breakdown}

analytical.kable(tss)

```

Many of these analytical methods are sensible and we can keep the majority of the data. One glaring issue is that more than 2 million observations have an analytical method of NA. What should we do with these samples? Throw out half of our data because the method is not verifiable? Or keep it knowing that some of the data might be using incompatable methods. 

#### TSS removing nonsensical analytical TSS methods

To keep the most data possible, we are making the explicit choice to only exclude methods that are clearly wrong (Ammonia content is not an appropriate TSS method). This means we are keeping the more than 2 million observatiosn with an analytical method of NA. While there are a variety of methods for estimating TSS, they can only differ so much, given that the primary goal is to get the mass of suspended matter per unit water volume. We assume most of these NA measurements were simply not recorded because the method used was a well-known method (like sediment concentratino by filtration). 

The code below is essentially a list of parameters we do not want to keep. 


```{r tss analytical method filtering}
#There are a lot of parameter codes so we are just going to use a grepl command with key words that definitely disqualify the sample

non.sensical.tss.methods <- tss %>%
  filter(grepl("Oxygen|Nitrogen|Ammonia|Metals|E. coli|Carbon|Anion|Cation|Phosphorus|Silica|PH|HARDNESS|Nutrient|Turbidity|Temperature|Nitrate|Conductance|Alkalinity|Chlorophyll",analytical_method,ignore.case=T))


tss.filtered <- tss %>%
  filter(!analytical_method %in% non.sensical.tss.methods$analytical_method)

print(paste('We dropped', round(nrow(non.sensical.tss.methods)/nrow(tss)*100,2),'% of samples, because the method used did not make sense. These methods are:'))

p(unique(non.sensical.tss.methods$analytical_method),wrap='',sep=' - ') #Nice function for printing long vectors horizontally separated by dash
```


### TSS depth of sampling

For TSS some sites also have the water depth of sample, which is very useful for validating whether or not the sample will reflect satellite observation of the same water parcel. However, most of the data doesn't have this depth of sampling data and it requires a bit of its own munging, since the sampling depth comes down in a range of units. Here we make the choice to not filter by depth of sample, but we show a histogram of sampling depths for sites that do have it. Most are near surface < 5 m. 

```{r depth breakdown}
#Define a depth lookup table to convert all depth data to meters. 
depth.lookup <- tibble(sample_depth_unit=c('cm','feet','ft','in','m','meters','None'),
                       depth_conversion=c(1/100,.3048,.3048,0.0254,1,1,NA)) 

#Join depth lookup table to tss data
tss.depth <- inner_join(tss,depth.lookup,by=c('sample_depth_unit')) %>%
  #Some depth measurements have negative values (assume that is just preference)
  #I also added .01 meters because many samlples have depth of zero assuming they were
  # taken directly at the surface
  mutate(harmonized_depth=abs(sample_depth*depth_conversion)+.01)

# We lose lots of data by keeping only data with depth measurements
print(paste('If we only kept samples that had depth information we would lose',round((nrow(tss)-nrow(tss.depth))/nrow(tss)*100,1),'% of samples'))


ggplot(tss.depth,aes(x=harmonized_depth)) + 
  geom_histogram(bins=100) + 
  scale_x_log10(limits=c(0.01,10^3),breaks=c(.1,1,10,100)) 
```

If we ignore all these additional data streams and simply assume SSC and TSS are generally near surface water samples collected with compatible field sampling and analytical methods. Then we can simply get rid of samples that have nonsensical units.

## TSS Unit Harmonization

### TSS disharmony

As with secchi disk depth, we expect certain units to be associated with total suspended solids or suspended sediment concentration. These include mass per volume measurements like: mg/l, g/l, ug/l and others. 

TSS does come with one less obvious parameter which is %. Any sample with a % unit is most commonly a sample where suspended sediments were split into particle size fractions. The relative proportion of clay, silt, and sand can have important impacts on the reflectance properties of water, so this is a useful parameter to keep, though it will require some exploration, using the additional data column that we relabeld as "particle_size."

#### TSS particle size fractionation

The table below shows all of the various particle fraction categories held within the TSS category. About half of the total observations (760,000) that use "%" as a unit are actually estimating the fraction of particles that are smaller than sand (<0.0625). The rest of the particle fractionation size classes are spread across *29* other particle fractions. This leaves us with a difficult choice. If we kept all of this data, we would widen our final dataset by 29 rows, with very few likely overpasses in a dataset of less than 80k observations per fraction category before checking for sites that are Landsat visible and were collected on relatively cloud free days. If we throw away all of the % data, we use valuable information that may help explain variability between sites with similar TSS but different reflectance values based on the particle size fractionation. Here, we will opt for an intermediate approach and keep only the > 300,000 observations that simply describe the fraction of sand in a sample (<0.0625 mm). 

```{r, fig.width=5}
#Select only units for %
tss.p <- tss %>%
  filter(units == '%') 

#look at the breakdown of particle sizes
tss.p %>%
  group_by(particle_size) %>%
  summarize(count=n()) %>%
  kable(.,'html',caption='All particle size fractions and their count') %>%
  kable_styling() %>%
  scroll_box(width='600px',height='400px')

#Keep only the sand fraction data (~50% of the data)
sand.harmonized  <- tss.p %>%
  filter(particle_size %in%  c('< 0.0625 mm','sands')) %>%
  mutate(conversion=NA,
         harmonized_parameter='p.sand',
         harmonized_value=value,
         harmonized_unit='%')


```


#### TSS dropping bad units

Now that we have split out the TSS values that had "%" units, we can deal with and drop the more nonsensical or missing units. The table below will also print out the number of "%" observations that we drop, but, remember, we kept about half of these in the above code. 

Here we will convert all remaining sediment values to units of mg/L and drop any non mass/volume units. 


```{r}
#Make a tss lookup table
tss.lookup <- tibble(units=c('mg/l','g/l','ug/l','ppm'),
                        conversion = c(1,1000,1/1000,1))


unit.disharmony(tss,tss.lookup)



```

### TSS harmony in mg/l

Now we can convert all TSS measurements to untis of 'mg/l.' We do need to do one final splitting of the data because there is another parameter name called "Fixed suspended solids." Fixed suspended solids are essentialy the inorganic component of a sediment sample that remains after kiln drying at 550&deg;F. We will relable these as a harmonized parameter 'Total inorganic sediment' or tis.

```{r tss harmony}
#Join to the lookup table and harmonize units

tss.tis.harmonized <- tss %>%
  inner_join(tss.lookup,by='units') %>%
  mutate(harmonized_parameter = 'tss',
         harmonized_value=value*conversion,
         harmonized_unit='mg/l') %>%
  #Change harmonized parameter to tis for parameter "fixed suspended solids"
  mutate(harmonized_parameter = ifelse(parameter == 'Fixed suspended solids','tis',harmonized_parameter))

rm(tss,tss.depth,tss.filtered,tss.lookup,tss.p,non.sensical.tss.methods,depth.lookup)
gc()
```

## TSS SSC empirical check
```{r}

names(tss.tis.harmonized)
ssc.tss <- tss.tis.harmonized %>%
  filter(parameter %in% c('Total suspended solids','Suspended Sediment Concentration (SSC)')) %>%
  select(date,date_time,SiteID,parameter,harmonized_value) %>%
  distinct(date_time,SiteID,.keep_all=T) %>%
  spread(key=parameter,value=harmonized_value) %>% 
  rename(tss=`Total suspended solids`,ssc=`Suspended Sediment Concentration (SSC)`) 

ssc.tss %>%
  filter(!is.na(ssc)) %>%
  summary(.)
```


# DOC

Dissolved organic carbon (DOC) is a complex series of parameters, methods, and unit combinations. We will not be examining particulate organic carbon, or total organic carbon.


First let's read in the data. 

```{r doc read}

#Summarize by characteristic name and unit code
doc <- read_feather('1_wqdata/out/wqp/all_raw_doc.feather') %>%
  wqp.renamer(.) 

```


### DOC sample fraction and sample methods

The water quality portal does not have a category for "Dissolved Organic Carbon," so we pulled three parameter names that might capture this category. 'Total Carbon', 'Organic Carbon', and 'Non-purgeable Organic Carbon (NPOC)'. For our purposes NPOC and Organic Carbon are exchnageable parameter names. In this data, there is a key column that we labeled 'fraction', which declares what fraction of the carbon pool is being reported. For purposes of this work, we are only keeping the fraction that indicates dissolved organic carbon, which can include fraction names like 'Dissolved' or 'Filterable.' The full list of fraction names and parameter names. 


```{r doc fraction}

doc %>%
  group_by(fraction) %>%
  summarize(count=n()) %>% 
  arrange(desc(count)) %>%
  kable(.,'html',caption='All doc sample fraction names and their count') %>%
  kable_styling() %>%
  scroll_box(width='600px',height='400px')


```

#### Keeping only Dissolved Fraciton

Here we subset the data to only include the data that we know is the Dissolved Organic Carbon pool. So far this is without regard to differences in analytical method. 

```{r keep doc fraction}
doc.fraction.names <- c('Dissolved','Filterable','Filtered, lab','Filtered, field')
doc.dissolved <- doc %>%
  filter(fraction %in% doc.fraction.names)


print(paste('we dropped',nrow(doc)-nrow(doc.dissolved),'samples because they were not labeled as dissolved'))
```


## DOC methods

Here, we'll explore method, and unit combinations and trim the data down a lot to keep only the most useful data. 

### DOC sample methods

As with TSS we are not going to filter our DOC data by sample method but the table of sample methods are provided here. 

```{r doc sample methods}
sample.kable(doc.dissolved)
```


### DOC analytical method

After removing the non "dissolved" fraction of carbon observations we are left with ~ 650,000 samples. Here we will remove analytical methods that explicitly do not make sense. As with TSS we will keep samples with analytical methods labeled as NA, assuming that they were done in a way that is exchangeable with other methods. This is a potentially erroneous assumption. 

```{r}
analytical.kable(doc.dissolved)
```


#### DOC removing nonsensical analytical methods
```{r}
doc.nonsense.methods <- doc.dissolved %>%
  filter(grepl("Oxygen|Nitrogen|Ammonia|Metals|E. coli|Anion|Cation|Phosphorus|Silica|PH|HARDNESS|Nutrient|Turbidity|Nitrate|Conductance|Alkalinity|Chlorophyll|Solids",analytical_method,ignore.case=T)) %>%
  filter(analytical_method != 'Temperature')


doc.filtered <- doc.dissolved %>%
  filter(!analytical_method %in% doc.nonsense.methods$analytical_method)

print(paste('We dropped', round(nrow(doc.nonsense.methods)/nrow(doc)*100,2),'% of samples, because the method used did not make sense. These methods are:'))

  
p(unique(doc.nonsense.methods$analytical_method),wrap='',sep=' - ') 
```

## DOC Units


As with TSS we generally expect DOC units to be in units of mass per unit volume, but we have many more possible variations of methods used to extract DOC values.

```{r}
unit.kable(doc.filtered)
```

Wow that is great. The vast majority of data is in a sensible unit (mg/L). We'll harmonize the remaining mass/volume units (ppm/ug/L) and drop the NAs and % units. Looks like sampling by `sample fraction` column cuts out a lot of the potential disharmony in units. 


### DOC unit disharmony
doc.filtered %>%

```{r}
#Setup a lookup table so that final units are all in mg/L. 
doc.lookup <- tibble(units=c('mg/l','ppm','ug/l'),
                        conversion = c(1,1,.001))

unit.disharmony(doc.filtered,doc.lookup)
```

## DOC harmony

The final step. Convert all convertable units to mg/l!

```{r}
doc.harmonized <- doc.filtered %>%
  inner_join(doc.lookup,by='units') %>%
  mutate(harmonized_parameter = 'doc',
         harmonized_value=value*conversion,
         harmonized_unit='mg/L')

rm(doc,doc.dissolved,doc.filtered,doc.lookup,doc.nonsense.methods)
```




# Chlorophyll

Chlorophyll concentration is a good proxy for algal biomass, but it may be the hardest parameter to harmonize because of a large array of diverse methods and measurements. Fist let's drop measurements that were not water samples (benthic chlorophyll)

```{r Chlorophyll}
#Read in the raw data from '1_wqdata/out'
chl <- read_feather('1_wqdata/out/wqp/all_raw_chlorophyll.feather') %>%
  wqp.renamer() 
```


## Chlorophyll a only

Here we are reducing the harmonization difficulty associated with chlorphyll by only keeping Chlorophyll a measurements, which is by far the most common measurement. But let's first look at all the various chlorophyll names we pulled down from the water quality portal. 


```{r chl all }

chl %>%
   group_by(parameter) %>%
   summarize(count=n()) %>% 
   arrange(desc(count)) %>%
   kable(.,'html',caption='All chlorophyll parameter names and their count') %>%
   kable_styling() %>%
   scroll_box(width='600px',height='400px')

```

One key parameter we are deciding to drop here is the Chl a, uncorrected for pheophytin. Pheophytin is a biproduct of chlorophyll degradation that can be generated by the processes used to extract chlorophyll from samples. Samples that do not correct for pheophytin can consistently underestimate in situ chlorophyll concentration, so we are choosing to drop these > 250,000 observations in addition to other non-chlorophyll a samples

### Chlorophyll a parameter disharmony

We are dropping the below parameter names
```{r chl throw away}

chl.a.names <- c('Chlorophyll a','Chlorophyll a (probe relative fluorescence)','Chlorophyll a, corrected for pheophytin','Chlorophyll a (probe)','Chlorophyll a, free of pheophytin', 'Chlorophyll a - Phytoplankton (suspended)') 

chl %>%
  filter(!parameter %in% chl.a.names) %>%
  group_by(parameter) %>%
  summarize(count=n()) %>%
  kable(.,'html',caption='All dropped chlorophyll parameter names and their count') %>%
  kable_styling() %>%
  scroll_box(width='600px',height='400px')
```

### Chlorophyll a keep

```{r chl a keepers}

chl.a <- chl %>%
  filter(parameter %in% chl.a.names)

```


## Chlorophyll a sample fraction

Now that we are only keeping the chlorophyll a fraction, we can start removing disharmony in the sample fraction, analytical method, and units categories. We'll start with the sample fraction

### Chlorophyll a all fractions
```{r}
chl.a %>%
   group_by(fraction) %>%
   summarize(count=n()) %>% 
   arrange(desc(count)) %>%
   kable(.,'html',caption='All chlorophyll sample fractions and their count') %>%
   kable_styling() %>%
   scroll_box(width='600px',height='400px')

```


This table highlights essentially four dominant categories for chlorophyll a sample fraction: Total (not-filtered), Filtered, Particle, and NA. The NA category is the most concenrting as this makes up almost 1/4 of the remaining data. There is some chance that downstream `analytical_method` cleaning will help clarify the NA category, but we won't know that until later downstream, so for now we will keep NA. Next, we need to decide which type of Chlorophyll measurements to keep, which given that most of the data is either total or dissolved, we will keep both. [Previous work](https://epic.awi.de/16281/1/Kne2007b.pdf) has shown that the filtering on Chlorophyll a samples captures 10-20% of the chlorophyll. Given the scope of this project and similar decisisons made between SSC and TSS, we are electing to combine Total and Dissolved chlorophyll a into one category and drop the particle fraction.  

### Chlorophyll fraction keep

```{r}
chl.particles <- c('Non-Filterable (Particle)','Suspended','Non-filterable','<Blank>','Acid Soluble')

chl.a.fraction <- chl.a %>%
  filter(!fraction %in% chl.particles)
```


## Chlorophyll a Methods

### Chlorophyll a sample methods

As with all other parameters we are not filtering by sample method

```{r chl sample method}
sample.kable(chl.a.fraction)

```

### Chlorophyll a analytical methods

```{r}
analytical.kable(chl.a.fraction)

```



#### Chlorophyll a removing nonsensical analytical methods

There are quite a few different analytical methods for chlorophyll analysis. Unfortunately the most common category is NA. As with previous parameters we can use this category to simply remove clearly non-sensical methods and keep all others including NA and blank.
```{r}
chl.a.nonsense.methods <- chl.a.fraction %>%
  filter(grepl("Oxygen|Nitrogen|Ammonia|Metals|Anion|Cation|Phosphorus|Silica|HARDNESS|Nutrient|Turbidity|Nitrate|Conductance|Alkalinity|Solids",analytical_method,ignore.case=T)) %>%
  filter(analytical_method != 'Temperature',
         analytical_method != 'PH')
  
chl.a.filtered <- chl.a.fraction %>%
  filter(!analytical_method %in% chl.a.nonsense.methods$analytical_method)

print(paste('We dropped', round(nrow(chl.a.nonsense.methods)/nrow(chl)*100,2),'% of samples, because the method used did not make sense. These methods are:'))

  
p(unique(chl.a.nonsense.methods$analytical_method),wrap='',sep=' - ') 
```



## Chlorophyll a units


As with TSS and DOC we generally expect Chlorophyll a units to be in units of mass per unit volume.

```{r}
unit.kable(chl.a.filtered)

```

Here again, the  majority of data is in a sensible unit (ug/L). We'll harmonize the remaining mass/volume units (ppm,mg/L) and drop the NAs and % units. We'll harmonize Chlorophyll a to the most common unit in the data (ug/L). 


### Chlorophyll a unit disharmony


```{r}
#Setup a lookup table so that final units are all in mg/L. 
chl.lookup <- tibble(units=c('mg/l','ppm','ug/l','mg/m3','ppb','mg/cm3','ug/ml','mg/ml'),
                        conversion = c(1000,1000,1,1,1,1000000,1000,1000000))

unit.disharmony(chl.a.filtered,chl.lookup)

```

## Chl harmony

The final step. Convert all convertable units to mg/l!

```{r}
chl.a.harmonized <- chl.a.filtered %>%
  inner_join(chl.lookup,by='units') %>%
  mutate(harmonized_parameter = 'chl.a',
         harmonized_value=value*conversion,
         harmonized_unit='ug/L')


rm(chl,chl.a,chl.a.filtered,chla.a.fraction,chl.a.nonsense.methods,chl.loookup)
```

Another call to gc() to clear memory again
```{r}
gc()
```


# CDOM 


```{r cdom read}

#Summarize by characteristic name and unit code
cdom <- read_feather('1_wqdata/out/wqp/all_raw_cdom.feather') %>%
  wqp.renamer(.) 

```


### CDOM sample fraction and sample methods

The water quality portal has a single call for CDOM: `'Colored dissolved organic matter (CDOM)'`. Fortunately this name includes some key metrics, the parameter is the
dissolved fraction of the carbon pool and the colored portion. Still, we
need to do some filtering based on analytical method. 


## CDOM methods

Here, we'll explore method, and unit combinations and trim the data down a lot to keep only the most useful data. 

### CDOM sample methods

As with TSS we are not going to filter our CDOM data by sample method but the table of sample methods are provided here. 

```{r cdom sample methods}
sample.kable(cdom)
```


### DOC analytical method

There are lots of methods possible for measuring CDOM, with either in-situ probes
or with fluoremters in the lab. Unfortunately the vast majority of CDOM data
has an "NA" for analytical method so we won't filter by it. 

```{r cdom analytical}
analytical.kable(cdom)
```



## CDOM Units


Unlike all other parameters, CDOM does not have a single, overwhelmingly, dominant
way of recording CDOM concentration. ONe common unit is the Relative Fluorescence Unit 
(RFU), which gives an estimate of CDOM, but does not necessarily map onto another
unit (ug/L). Distressingly, almost a third of the data has no units (None). At 
best we would be able to keep only  `r cdom %>% filter(units == 'RFU') %>% nrow(.) ` samples of CDOM measurements, which given the reductive fraction of overpasses, would
leave less than 100 measurements of CDOM and satellite coverage. This can be revisited 
in the future, but such little quantities of data do not match the goals of this project.

```{r cdom units}
unit.kable(cdom)
```



# Bind and save the harmonized data

At the end of all this harmonization we want a data frame with parameter columns that hold the final harmonized values, along with a date, lat, long, and siteid. But first we need to do some more quality control on the full, harmonized dataset. This additional data munging can be found in the script `2_combined_wqp_munge.Rmd`

```{r}
#Downstream code can't handle the size of the single TSS data file so we will split that into a few separate datasets  instead of one

#First just the TIS data
tis.harmonized <- tss.tis.harmonized %>%
  filter(harmonized_parameter=='tis')

#Add an index to help with splitting
tss.harmonized <- tss.tis.harmonized %>%
  filter(harmonized_parameter=='tss') %>%
  arrange(SiteID,date) %>%
  mutate(index=1:nrow(.))



#Bind all the harmonized data together
harmonized.datasets <- list(chl.a.harmonized,doc.harmonized,tis.harmonized,tss.harmonized,sand.harmonized,secchi.harmonized)

h.names <- c('chl.a','doc','tis','tss','sand','secchi')
```

# Check for observations at a ridiculous depth
```{r}
#Before exporting the harmonized data we can do one more quality check
singular.harmony <- map_dfr(harmonized.datasets,rbind)

has.depth <- singular.harmony %>%
  filter(!is.na(sample_depth)) 

print(paste('We would lose',100*round(1-(nrow(has.depth)/nrow(singular.harmony)),3),'% of samples if we kept only observations that have sample depth recorded'))


depth.lookup <- tibble(sample_depth_unit=c('cm','feet','ft','in','m','meters','None'),
                       depth_conversion=c(1/100,.3048,.3048,0.0254,1,1,NA)) 

shallow.depth <- has.depth %>%
  left_join(depth.lookup,by='sample_depth_unit') %>%
  mutate(harmonized_depth = abs(sample_depth)*depth_conversion) %>% #some depth is recorded as a negative value
  
  filter(harmonized_depth < 100)


summary(shallow.depth$harmonized_depth)
print(paste('We lose',round((nrow(has.depth)-nrow(shallow.depth))/nrow(singular.harmony)*100,3),' % of samples by restricting data to less than 100m'))




```


```{r}
#Remove extraneous columns
extraneous <- function(df){
  df <- df %>%
    mutate(index = 1:nrow(.)) %>%
    filter(!is.na(harmonized_value)) %>%
    ungroup() %>%
    left_join(depth.lookup,by='sample_depth_unit') %>%
    mutate(harmonized_depth = abs(sample_depth)*depth_conversion) %>%
    filter(harmonized_depth < 100 | is.na(harmonized_depth)) %>%
    #Remove extraneous columns
    dplyr::select(-units,-org,-org_id,-sample_method,
                  -sample_depth,-sample_depth_unit,
                  -particle_size,-media,-fraction,
                  -status,-conversion) 
}


#Remove columns and save
for(i in 1:length(harmonized.datasets)){
  print(i)
  dat <- extraneous(harmonized.datasets[[i]])
  write_feather(dat,
                path=paste0('1_wqdata/tmp/harmonized/',
                            h.names[i],'_harmony.feather'))
}

# tss.cleaned <- tss.harmonized %>%
#   extraneous(.)
# write_feather(tss.cleaned,path=paste0('1_wqdata/tmp/harmonized/',
#                             'tss','_harmony.feather'))


```
