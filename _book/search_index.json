[["index.html", "1 AquaMatch data harmonization process", " 1 AquaMatch data harmonization process This bookdown documents the harmonization process for raw data downloaded from the Water Quality Portal (WQP) and used to build the AquaMatch dataset. The data from the Water Quality Portal (WQP) includes data obtained from a wide range of data providers with varying acquisition and analysis methods and multiple characteristicNames. In this workflow, we harmonize by parameter groups (e.g., “chlorophyll a”), which may include multiple characteristicNames. For example, chlorophyll-related characteristicNames include “Chlorophyll a”, “Chlorophyll a, corrected for pheophytin”, “Chlorophyll b”, and “Chlorophyll c” among several others. Only a subset of these will be of interest to us in building our “chlorophyll a” parameter group. Each of the parameter groups can be sampled and analyzed using a variety of methods, some of which are directly interoperable, and others which are not. This harmonization process allows us to filter out or flag data that may not have enough information, creating a database of the WQP entries with varying degrees of direct interoperability. This harmonization procedure results in two datasets per parameter. The first is a harmonized dataset that includes all of the original WQP columns in addition to those introduced in this workflow. The second is the output of all harmonization steps, including aggregation to the median value where simultaneous records occur (see section @ref(aggregate-simultaneous-records) for our definition of simultaneous records). We believe that most users will only use the aggregated dataset, but we provide the unaggregated version for those who would like to make different aggregation decisions. This document first describes selections made while downloading WQP data, the “pre-harmonization” process that data for all parameters go through, and then how the chlorophyll a, dissolved organic carbon (DOC), Secchi disc depth, and total suspended solids (TSS) parameter groups are each filtered and harmonized. "],["download-process.html", "2 Download process", " 2 Download process 2.0.1 Catalogue existing data The download process begins by cataloging the existing data that is available in the WQP. To do this the user specifies parameters and their corresponding characteristicName for retrieving data from the WQP. Below are the current parameters and their characteristicName as defined in the configuration YAML, 1_inventory/cfg/wqp_codes.yml. Data for these parameters are requested from the WQP within a spatial grid that is mapped in the next section. Code yaml_contents &lt;- read_yaml(&quot;../1_inventory/cfg/wqp_codes.yml&quot;) names_yaml &lt;- names(yaml_contents) map_df(.x = names_yaml, .f = ~yaml_contents[.x] %&gt;% as_tibble() %&gt;% rename(characteristicName = 1) %&gt;% mutate(parameter = .x) %&gt;% select(parameter, characteristicName)) %&gt;% kable() %&gt;% kable_material() %&gt;% collapse_rows(columns = 1, valign = &quot;top&quot;) parameter characteristicName chlorophyll Chlorophyll a chlorophyll Chlorophyll a (probe relative fluorescence) chlorophyll Chlorophyll a, corrected for pheophytin chlorophyll Chlorophyll a (probe) chlorophyll Chlorophyll a, free of pheophytin chlorophyll Chlorophyll a, uncorrected for pheophytin chlorophyll Chlorophyll a - Phytoplankton (suspended) doc Organic carbon doc Total carbon doc Hydrophilic fraction of organic carbon doc Non-purgeable Organic Carbon (NPOC) secchi Depth, Secchi disk depth secchi Depth, Secchi disk depth (choice list) secchi Secchi Reading Condition (choice list) secchi Secchi depth secchi Water transparency, Secchi disc tss Total suspended solids tss Total Particulate Matter tss Total Suspended Particulate Matter 2.0.2 Maps of data spread: Maps are presented below with counts of records across a grid. The grid is how records are grouped in download requests to the Water Quality Portal. Note: The counts here are for raw data that are not filtered or harmonized. Code # Combine counts in each grid_id with the grid polygons grid_counts &lt;- left_join(x = global_grid, y = site_counts %&gt;% count(grid_id), by = c(&quot;id&quot; = &quot;grid_id&quot;)) %&gt;% st_transform(crs = 9311) state_selection &lt;- states(progress_bar = FALSE) %&gt;% st_transform(crs = 9311) ## Retrieving data for the year 2021 Code # Conterminous US map: conterminous_us &lt;- state_selection %&gt;% filter(!(NAME %in% c(&quot;Alaska&quot;, &quot;Hawaii&quot;, &quot;American Samoa&quot;, &quot;Guam&quot;, &quot;Puerto Rico&quot;, &quot;United States Virgin Islands&quot;, &quot;Commonwealth of the Northern Mariana Islands&quot;))) ggplot() + geom_sf(data = grid_counts, aes(fill = n)) + geom_sf(data = conterminous_us, fill = NA, color = &quot;black&quot;) + xlab(NULL) + ylab(NULL) + coord_sf(xlim = c(min(st_coordinates(conterminous_us)[,&quot;X&quot;]), max(st_coordinates(conterminous_us)[,&quot;X&quot;])), ylim = c(min(st_coordinates(conterminous_us)[,&quot;Y&quot;]), max(st_coordinates(conterminous_us)[,&quot;Y&quot;]))) + scale_fill_viridis_c(&quot;Record count&quot;, trans = &quot;log10&quot;, labels = scales::label_number(), na.value = &quot;white&quot;, breaks = c(1, 10, 100, 1000, 10000)) + ggtitle(&quot;Conterminous US&quot;) + theme_bw() Code # Alaska map: AK &lt;- state_selection %&gt;% filter(NAME == &quot;Alaska&quot;) ggplot() + geom_sf(data = grid_counts, aes(fill = n)) + geom_sf(data = AK, fill = NA, color = &quot;black&quot;) + xlab(NULL) + ylab(NULL) + coord_sf(xlim = c(min(st_coordinates(AK)[,&quot;X&quot;]), max(st_coordinates(AK)[,&quot;X&quot;])), ylim = c(min(st_coordinates(AK)[,&quot;Y&quot;]), max(st_coordinates(AK)[,&quot;Y&quot;]))) + scale_fill_viridis_c(&quot;Record count&quot;, trans = &quot;log10&quot;, labels = scales::label_number(), na.value = &quot;white&quot;, breaks = c(1, 10, 100, 1000, 10000)) + ggtitle(&quot;Alaska&quot;) + theme_bw() Code # Hawaii map: HI &lt;- state_selection %&gt;% filter(NAME == &quot;Hawaii&quot;) ggplot() + geom_sf(data = grid_counts, aes(fill = n)) + geom_sf(data = HI, fill = NA, color = &quot;black&quot;) + xlab(NULL) + ylab(NULL) + coord_sf(xlim = c(min(st_coordinates(HI)[,&quot;X&quot;]), 0.9 * max(st_coordinates(HI)[,&quot;X&quot;])), ylim = c(1.1 * min(st_coordinates(HI)[,&quot;Y&quot;]), max(st_coordinates(HI)[,&quot;Y&quot;]))) + scale_fill_viridis_c(&quot;Record count&quot;, trans = &quot;log10&quot;, labels = scales::label_number(), na.value = &quot;white&quot;, breaks = c(1, 10, 100, 1000, 10000)) + ggtitle(&quot;Hawaii&quot;) + theme_bw() Code # American Samoa map: AS &lt;- state_selection %&gt;% filter(NAME %in% c(&quot;American Samoa&quot;)) ggplot() + geom_sf(data = grid_counts, aes(fill = n)) + geom_sf(data = AS, fill = NA, color = &quot;black&quot;) + xlab(NULL) + ylab(NULL) + coord_sf(xlim = c(1.025 * min(st_coordinates(AS)[,&quot;X&quot;]), 0.975 *max(st_coordinates(AS)[,&quot;X&quot;])), ylim = c(1.05 * min(st_coordinates(AS)[,&quot;Y&quot;]), max(st_coordinates(AS)[,&quot;Y&quot;]))) + scale_fill_viridis_c(&quot;Record count&quot;, trans = &quot;log10&quot;, labels = scales::label_number(), na.value = &quot;white&quot;, breaks = c(1, 10, 100, 1000, 10000)) + ggtitle(&quot;American Samoa&quot;) + theme_bw() Code # Guam &amp; Commonwealth of the Northern Mariana Islands map GU_CNMI &lt;- state_selection %&gt;% filter(NAME %in% c(&quot;Guam&quot;, &quot;Commonwealth of the Northern Mariana Islands&quot;)) ggplot() + geom_sf(data = grid_counts, aes(fill = n)) + geom_sf(data = GU_CNMI, fill = NA, color = &quot;black&quot;) + xlab(NULL) + ylab(NULL) + coord_sf(xlim = c(1.025 * min(st_coordinates(GU_CNMI)[,&quot;X&quot;]), 0.975 * max(st_coordinates(GU_CNMI)[,&quot;X&quot;])), ylim = c(0.95 * min(st_coordinates(GU_CNMI)[,&quot;Y&quot;]), 1.05 * max(st_coordinates(GU_CNMI)[,&quot;Y&quot;]))) + scale_fill_viridis_c(&quot;Record count&quot;, trans = &quot;log10&quot;, labels = scales::label_number(), na.value = &quot;white&quot;, breaks = c(1, 10, 100, 1000, 10000)) + ggtitle(&quot;Guam &amp; Commonwealth of the Northern Mariana Islands&quot;) + theme_bw() Code # Puerto Rico &amp; United States Virgin Islands map: PR_VI &lt;- state_selection %&gt;% filter(NAME %in% c(&quot;Puerto Rico&quot;, &quot;United States Virgin Islands&quot;)) ggplot() + geom_sf(data = grid_counts, aes(fill = n)) + geom_sf(data = PR_VI, fill = NA, color = &quot;black&quot;) + xlab(NULL) + ylab(NULL) + coord_sf(xlim = c(0.95 * min(st_coordinates(PR_VI)[,&quot;X&quot;]), 1.05 * max(st_coordinates(PR_VI)[,&quot;X&quot;])), ylim = c(1.075 * min(st_coordinates(PR_VI)[,&quot;Y&quot;]), 0.925 * max(st_coordinates(PR_VI)[,&quot;Y&quot;]))) + scale_fill_viridis_c(&quot;Record count&quot;, trans = &quot;log10&quot;, labels = scales::label_number(), na.value = &quot;white&quot;, breaks = c(1, 10, 100, 1000, 10000)) + ggtitle(&quot;Puerto Rico &amp; United States Virgin Islands&quot;) + theme_bw() "],["tiering-flagging-and-quality-control-philosophy.html", "3 Tiering, flagging, and quality control philosophy 3.1 Handling NA values 3.2 Heterogenous data 3.3 Simultaneous records", " 3 Tiering, flagging, and quality control philosophy The variety of data providers, parameters, and methods in the WQP inevitably results in a heterogenous dataset that requires rigorous quality control before analytical use. 3.1 Handling NA values Columns related directly to the interoperability of data in the WQP, specifically field and lab methodology and depth-related columns, often contain many NAs in part due to inconsistent entry across data providers. A highly restrictive filtering of the WQP that requires completed data fields would result in very limited data, in part, due to the prevalence of these NA values. Therefore, we are building this dataset to resolve as many NAs as possible, but to also include NAs within an “inclusive” data tier if all columns of interest are not resolvable. 3.2 Heterogenous data In addition to NA values, WQP entries can be heterogenous for reasons such as: Having a variety of analytical methods with different levels of precision and accuracy that can be used to quantify the same parameter Having a variety of names or descriptions of the same (e.g., analytical) method across different organizations Containing data for one parameter obtained by multiple sampling methods with varying levels of interoperability or necessary metadata Having information relevant to assessing data reliability or method choice spread across multiple columns Containing observations with sample collection methods and analytical methods that are incompatible Having data with differing levels of meta data In order to control for some of this variation and provide end-users with something more readily navigable we have incorporated several tiers and flagging systems into the AquaSat v2 dataset: Analytical method tiering: Tiers indicating the interoperability of data based on the analytical method used to acquire measurements Field flags: Flags indicating whether the sample collection method is consistent with the analytical method Depth flags: Flags indicating the type of depth measurement or completeness of the depth measurement 3.2.1 Analytical method tiering The ResultAnalyticalMethod.MethodName column from the WQP is the primary column we use for determining which analytical method tier each record falls within. Details on how each parameter’s methods were sorted into tiers can be found in its corresponding harmonization chapter. The primary purpose of our analytical method tiering is to determine the reliability and accuracy of each analytical method across data providers and throughout time for each parameter in the AquaSat v2 dataset. We developed the following categories for this column, which is denoted as analytical_tier in the final dataset: Tier 0: Restrictive. Data that are verifiably self-similar across organizations and time-periods and can be considered highly reliable and interoperable Tier 1: Narrowed. Data that we have good reason to believe are self-similar, but for which we can’t verify full interoperability across data providers Tier 2: Inclusive. Data that are assumed to be reliable and are harmonized to our best ability given the information available from the data provider. This tier includes NA or non-resolvable descriptions for the analytical method, which often make up the majority of methods descriptions for any given parameter. Because this tier represents many analytical methods, direct interoperability between samples is not guaranteed. 3.2.2 Field flags The field_flag column is used to check if the sample collection method (SampleCollectionMethod.MethodName) is reasonable (flag = 0), suspect (flag = 1), or inconclusive (flag = 2). “Reasonable” flags mean that the sample collection method and the analytical method or tier are in harmony with one another. “Suspect” flags are assigned when the sample collection method description isn’t consistent with what would be expected given the characteristicName and the ResultAnalyticalMethod.MethodName for a given record. “Inconclusive” or unknown flags are assigned to records with “inclusive” analytical tiers because these tiers include values such as NA, where it’s typically impossible to determine the appropriateness of a collection method for the sample record. The relationship between field flags and analytical tiers will vary by parameter and each harmonization chapter contains specific information for these different cases. 3.2.3 Depth flags There are four columns that explicitly contain depth information for a given WQP entry, all of which contain a variety of measurement units. Below is a list of the four columns and their definitions according to the {dataRetrieval} package documentation. ActivityDepthHeightMeasure.MeasureValue: “A measurement of the vertical location (measured from a reference point) at which an activity occurred.” ResultDepthHeightMeasure.MeasureValue: “A measurement of the vertical location (measured from a reference point) at which a result occurred.” Only in STORET ActivityTopDepthHeightMeasure.MeasureValue: “A measurement of the upper vertical location of a vertical location range (measured from a reference point) at which an activity occurred.” ActivityBottomDepthHeightMeasure.MeasureValue: “A measurement of the lower vertical location of a vertical location range (measured from a reference point) at which an activity occurred.” Each of the above columns has a corresponding column containing the “code that represents the unit for measuring the item”: ActivityDepthHeightMeasure.MeasureUnitCode ResultDepthHeightMeasure.MeasureUnitCode ActivityTopDepthHeightMeasure.MeasureUnitCode ActivityBottomDepthHeightMeasure.MeasureUnitCode 3.2.3.1 Pre-processing Prior to assigning the depth_flag we complete a few pre-processing steps: Convert the following (character) values to an explicit NA: “NA”, “999”, “-999”, “9999”, “-9999”, “-99”, “99”, “NaN” Convert depths in all four columns to meters from the depth unit listed by the data provider Create a single “discrete” sample depth column using a combination of the ActivityDepthHeightMeasure.MeasureValue and ResultDepthHeightMeasure.MeasureValue columns. We use ActivityDepth value when ResultDepth value is missing, and ResultDepth when ActivityDepth is missing. If both columns have values but disagree we use an average of the two. This pre-processing results in three “harmonized” columns reporting depth values in meters: harmonized_discrete_depth_value, harmonized_top_depth_value, harmonized_bottom_depth_value. Depth flags are assigned using the harmonized depth columns that result from the pre-processing steps above. If the record has no depth listed it is designated depth_flag = 0. A record with only discrete depth (listed in the harmonized_discrete_depth_value is given a depth_flag = 1. A record with top and/or bottom depth (harmonized_top_depth_value, harmonized_bottom_depth_value), indicating an integrated sample, is assigned depth_flag = 2, and any combination of discrete + top and/or bottom depths is assigned depth_flag = 3, where the sample depth(s) can not be reconciled with certainty. 3.2.4 General note Generally speaking, we avoid further classification for any WQP entry’s parameter methodology, tier, or flag unless there are at least 1% of observations with the same unresolved text. 3.3 Simultaneous records The WQP contains records that can be considered true duplicates and others where multiple non-identical measurements are recorded at the same time, place, and depth by the same organization. We deal with these within each parameter’s harmonization step by taking the median value from simultaneous observations. We also provide a total number of entries contributing to the median as well as the standard deviation of the mean for downstream users to apply their own filtering for this aggregated dataset. This is dealt with separately for each parameter so that specific accommodations can be made based on the tiering and value cleaning process for each parameter. Additionally, this step also requires us to group the dataset by a subset of its original columns in order to create aggregate groups, necessarily resulting in a reduced subset of columns in the final data product. To aide in back-joining for advanced AquaSat users, we provide a subgroup_id column identifying the grouping used to create the aggregated value. The subgroup_id is also present in an upstream, pre-aggregated dataset version that also contains all records prior to aggregation and the original WQP columns along with the columns created in the harmonization steps. The upstream, pre-aggregated dadtaset is the p3_chla_preagg_grouped pipeline target. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
